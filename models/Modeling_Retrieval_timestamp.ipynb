{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVmLzgzO_qey"
      },
      "source": [
        "# Modeling Notebook: Retrieval with multiple features\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ag6ftqYHFCiE"
      },
      "source": [
        "In this Retrieval model we are incorporatings timestamp data ('review_date' feature) and performing Convolutional Neural Networks (CNN) on product title. "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ],
      "metadata": {
        "id": "-7tE6FNPV6Yr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o85tAgdr_g6A",
        "outputId": "819faa7e-a647-422c-b732-0a392834bc96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.9.2)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow) (21.3)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.2.0)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.9.1)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.9.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (14.0.6)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.9.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.49.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.27.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (5.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (3.9.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2022.9.24)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (3.2.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow) (3.0.9)\n"
          ]
        }
      ],
      "source": [
        "! pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIhCpdSdA0Ww",
        "outputId": "e9438e90-7118-4803-b98e-5952659ac2d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 89 kB 7.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.7 MB 15.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 10.4 MB 17.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 578.0 MB 14 kB/s \n",
            "\u001b[K     |████████████████████████████████| 438 kB 74.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 77.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 5.9 MB 74.1 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "! pip install -q tensorflow-recommenders\n",
        "! pip install -q --upgrade tensorflow-datasets\n",
        "! pip install -q scann"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "fnw0ieejA3R9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pprint\n",
        "import tempfile\n",
        "\n",
        "from typing import Dict, Text\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow_recommenders as tfrs\n",
        "\n",
        "# import interactive table \n",
        "from google.colab import data_table\n",
        "data_table.enable_dataframe_formatter()\n",
        "\n",
        "# set seed\n",
        "tf.random.set_seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparing dataset"
      ],
      "metadata": {
        "id": "CULaa9CrWA8T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akyaDBMzOfa2",
        "outputId": "535c7381-ca8b-4c9d-d1d6-476f64a73fc6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# mount G-Drive and load data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# load data subset \n",
        "gdrive_path = '/content/drive/MyDrive/ModelingData'\n",
        "path = os.path.join(gdrive_path, \"ratings\")\n",
        "\n",
        "ratings = tf.data.Dataset.load(path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "products = ratings.map(lambda x: x['data']['product_title'])"
      ],
      "metadata": {
        "id": "bxUR3slitlNB"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "QIjRO75CB-PJ"
      },
      "outputs": [],
      "source": [
        "# Select the basic features.\n",
        "\n",
        "ratings = ratings.map(lambda x: {\n",
        "    'product_title': x['data']['product_title'],\n",
        "    'customer_id': x['data']['customer_id'], \n",
        "    'timestamp': tf.strings.to_number(tf.strings.regex_replace(x['data']['review_date'], \"-\", \"\"), tf.int32),\n",
        "    })"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare timestamp feature vocabulary\n",
        "\n",
        "timestamps = np.concatenate(list(ratings.map(lambda x: x[\"timestamp\"]).batch(100)))\n",
        "\n",
        "max_timestamp = timestamps.max()\n",
        "min_timestamp = timestamps.min()\n",
        "\n",
        "timestamp_buckets = np.linspace(\n",
        "    min_timestamp, max_timestamp, num=1000,\n",
        ")\n"
      ],
      "metadata": {
        "id": "zM2uYYW-wMMz"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# preparing feature vocabularies\n",
        "\n",
        "unique_product_titles = np.unique(np.concatenate(list(ratings.map(lambda x: x[\"product_title\"]).batch(1000))))\n",
        "unique_user_ids = np.unique(np.concatenate(list(ratings.batch(1_000).map(\n",
        "    lambda x: x[\"customer_id\"]))))"
      ],
      "metadata": {
        "id": "zZr087s_XgpW"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Query model"
      ],
      "metadata": {
        "id": "WjtA8JeVqTr9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_model = tf.keras.Sequential([\n",
        "  tf.keras.layers.StringLookup(\n",
        "      vocabulary=unique_user_ids, mask_token=None),\n",
        "  # We add an additional embedding to account for unknown tokens.\n",
        "  tf.keras.layers.Embedding(len(unique_user_ids) + 1, 32)\n",
        "])"
      ],
      "metadata": {
        "id": "l0DwQPDrq9AC"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# if using timestamp\n",
        "class UserModel(tf.keras.Model):\n",
        "\n",
        "  def __init__(self, use_timestamps):\n",
        "    super().__init__()\n",
        "\n",
        "    self._use_timestamps = use_timestamps\n",
        "\n",
        "    self.user_embedding = tf.keras.Sequential([\n",
        "        tf.keras.layers.StringLookup(\n",
        "            vocabulary=unique_user_ids, mask_token=None),\n",
        "        tf.keras.layers.Embedding(len(unique_user_ids) + 1, 32),\n",
        "    ])\n",
        "\n",
        "    if use_timestamps:\n",
        "      self.timestamp_embedding = tf.keras.Sequential([\n",
        "          tf.keras.layers.Discretization(timestamp_buckets.tolist()),\n",
        "          tf.keras.layers.Embedding(len(timestamp_buckets) + 1, 32),\n",
        "      ])\n",
        "      self.normalized_timestamp = tf.keras.layers.Normalization(\n",
        "          axis=None\n",
        "      )\n",
        "\n",
        "      self.normalized_timestamp.adapt(timestamps)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    if not self._use_timestamps:\n",
        "      return self.user_embedding(inputs[\"user_id\"])\n",
        "\n",
        "    return tf.concat([\n",
        "        self.user_embedding(inputs[\"user_id\"]),\n",
        "        self.timestamp_embedding(inputs[\"timestamp\"]),\n",
        "        tf.reshape(self.normalized_timestamp(inputs[\"timestamp\"]), (-1, 1)),\n",
        "    ], axis=1)"
      ],
      "metadata": {
        "id": "wqMCXEZiqTOP"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Candidate model"
      ],
      "metadata": {
        "id": "WdlH5ZlKrqKp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ProductModel(tf.keras.Model):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    max_tokens = 10_000\n",
        "\n",
        "    self.title_embedding = tf.keras.Sequential([\n",
        "      tf.keras.layers.StringLookup(\n",
        "          vocabulary=unique_product_titles, mask_token=None),\n",
        "      tf.keras.layers.Embedding(len(unique_product_titles) + 1, 32)\n",
        "    ])\n",
        "\n",
        "    self.title_vectorizer = tf.keras.layers.TextVectorization(\n",
        "        max_tokens=max_tokens)\n",
        "\n",
        "    self.title_text_embedding = tf.keras.Sequential([\n",
        "      self.title_vectorizer,\n",
        "      tf.keras.layers.Embedding(max_tokens, 32, mask_zero=True),\n",
        "      tf.keras.layers.GlobalAveragePooling1D(),\n",
        "    ])\n",
        "\n",
        "    self.title_vectorizer.adapt(products)\n",
        "\n",
        "  def call(self, titles):\n",
        "    return tf.concat([\n",
        "        self.title_embedding(titles),\n",
        "        self.title_text_embedding(titles),\n",
        "    ], axis=1)"
      ],
      "metadata": {
        "id": "4O16FIU7rk8Q"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Combined model"
      ],
      "metadata": {
        "id": "T8pd1uItsqNl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AmazonModel(tfrs.models.Model):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.query_model = tf.keras.Sequential([\n",
        "      user_model,\n",
        "      tf.keras.layers.Dense(32)\n",
        "    ])\n",
        "    self.candidate_model = tf.keras.Sequential([\n",
        "      ProductModel(),\n",
        "      tf.keras.layers.Dense(32)\n",
        "    ])\n",
        "    self.task = tfrs.tasks.Retrieval(\n",
        "        metrics=tfrs.metrics.FactorizedTopK(\n",
        "            candidates=products.batch(128).map(self.candidate_model),\n",
        "        ),\n",
        "    )\n",
        "\n",
        "  def compute_loss(self, features, training=False):\n",
        "    # We only pass the user id and timestamp features into the query model. This\n",
        "    # is to ensure that the training inputs would have the same keys as the\n",
        "    # query inputs. Otherwise the discrepancy in input structure would cause an\n",
        "    # error when loading the query model after saving it.\n",
        "    query_embeddings = self.query_model(features[\"customer_id\"])\n",
        "    product_embeddings = self.candidate_model(features[\"product_title\"])\n",
        "\n",
        "    return self.task(query_embeddings, product_embeddings)"
      ],
      "metadata": {
        "id": "BACaQM9Istiv"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AmazonModel(tfrs.models.Model):\n",
        "\n",
        "  def __init__(self, use_timestamps):\n",
        "    super().__init__()\n",
        "    self.query_model = tf.keras.Sequential([\n",
        "      UserModel(use_timestamps),\n",
        "      tf.keras.layers.Dense(32)\n",
        "    ])\n",
        "    self.candidate_model = tf.keras.Sequential([\n",
        "      ProductModel(),\n",
        "      tf.keras.layers.Dense(32)\n",
        "    ])\n",
        "    self.task = tfrs.tasks.Retrieval(\n",
        "        metrics=tfrs.metrics.FactorizedTopK(\n",
        "            candidates=products.batch(128).map(self.candidate_model),\n",
        "        ),\n",
        "    )\n",
        "\n",
        "  def compute_loss(self, features, training=False):\n",
        "    # We only pass the user id and timestamp features into the query model. This\n",
        "    # is to ensure that the training inputs would have the same keys as the\n",
        "    # query inputs. Otherwise the discrepancy in input structure would cause an\n",
        "    # error when loading the query model after saving it.\n",
        "    query_embeddings = self.query_model({\n",
        "        \"user_id\": features[\"customer_id\"],\n",
        "        \"timestamp\": features[\"timestamp\"],\n",
        "    })\n",
        "    product_embeddings = self.candidate_model(features[\"product_title\"])\n",
        "\n",
        "    return self.task(query_embeddings, product_embeddings)"
      ],
      "metadata": {
        "id": "bvENy7Iu1VPx"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implementing and Evaluating model"
      ],
      "metadata": {
        "id": "9267R5A1utkv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "f8BJNQgUC1DK"
      },
      "outputs": [],
      "source": [
        "# train-test split\n",
        "tf.random.set_seed(42)\n",
        "shuffled = ratings.shuffle(115120, seed=42, reshuffle_each_iteration=False)\n",
        "\n",
        "train = shuffled.take(92_096)\n",
        "test = shuffled.skip(92_096).take(23_024)\n",
        "\n",
        "cached_train = train.shuffle(115120).batch(2048)\n",
        "cached_test = test.batch(4096).cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "sDVi3bsnDofr"
      },
      "outputs": [],
      "source": [
        "# initiate model\n",
        "combined_model = AmazonModel(use_timestamps = True)\n",
        "combined_model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5-ef2mYPHNo",
        "outputId": "1f682a11-a052-4e8a-9d89-2a70bfb860bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'timestamp': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=int32>}. Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'timestamp': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=int32>}. Consider rewriting this model with the Functional API.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "45/45 [==============================] - 471s 10s/step - factorized_top_k/top_1_categorical_accuracy: 0.0014 - factorized_top_k/top_5_categorical_accuracy: 0.0016 - factorized_top_k/top_10_categorical_accuracy: 0.0018 - factorized_top_k/top_50_categorical_accuracy: 0.0033 - factorized_top_k/top_100_categorical_accuracy: 0.0048 - loss: 162047.1825 - regularization_loss: 0.0000e+00 - total_loss: 162047.1825\n",
            "Epoch 2/5\n",
            "45/45 [==============================] - 462s 10s/step - factorized_top_k/top_1_categorical_accuracy: 0.0039 - factorized_top_k/top_5_categorical_accuracy: 0.0062 - factorized_top_k/top_10_categorical_accuracy: 0.0083 - factorized_top_k/top_50_categorical_accuracy: 0.0229 - factorized_top_k/top_100_categorical_accuracy: 0.0372 - loss: 46727.1869 - regularization_loss: 0.0000e+00 - total_loss: 46727.1869\n",
            "Epoch 3/5\n",
            "45/45 [==============================] - 482s 11s/step - factorized_top_k/top_1_categorical_accuracy: 0.0556 - factorized_top_k/top_5_categorical_accuracy: 0.1048 - factorized_top_k/top_10_categorical_accuracy: 0.1467 - factorized_top_k/top_50_categorical_accuracy: 0.3039 - factorized_top_k/top_100_categorical_accuracy: 0.3799 - loss: 8205.6867 - regularization_loss: 0.0000e+00 - total_loss: 8205.6867\n",
            "Epoch 4/5\n",
            "45/45 [==============================] - 468s 10s/step - factorized_top_k/top_1_categorical_accuracy: 0.2386 - factorized_top_k/top_5_categorical_accuracy: 0.3521 - factorized_top_k/top_10_categorical_accuracy: 0.4299 - factorized_top_k/top_50_categorical_accuracy: 0.6203 - factorized_top_k/top_100_categorical_accuracy: 0.6865 - loss: 4387.8252 - regularization_loss: 0.0000e+00 - total_loss: 4387.8252\n",
            "Epoch 5/5\n",
            "45/45 [==============================] - 463s 10s/step - factorized_top_k/top_1_categorical_accuracy: 0.3210 - factorized_top_k/top_5_categorical_accuracy: 0.4790 - factorized_top_k/top_10_categorical_accuracy: 0.5721 - factorized_top_k/top_50_categorical_accuracy: 0.7558 - factorized_top_k/top_100_categorical_accuracy: 0.8092 - loss: 2775.5830 - regularization_loss: 0.0000e+00 - total_loss: 2775.5830\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'user_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'timestamp': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=int32>}. Consider rewriting this model with the Functional API.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "45/45 [==============================] - 464s 10s/step - factorized_top_k/top_1_categorical_accuracy: 0.3885 - factorized_top_k/top_5_categorical_accuracy: 0.6343 - factorized_top_k/top_10_categorical_accuracy: 0.7215 - factorized_top_k/top_50_categorical_accuracy: 0.8563 - factorized_top_k/top_100_categorical_accuracy: 0.8901 - loss: 1830.5084 - regularization_loss: 0.0000e+00 - total_loss: 1830.5084\n",
            "6/6 [==============================] - 99s 16s/step - factorized_top_k/top_1_categorical_accuracy: 4.3433e-05 - factorized_top_k/top_5_categorical_accuracy: 1.7373e-04 - factorized_top_k/top_10_categorical_accuracy: 2.6060e-04 - factorized_top_k/top_50_categorical_accuracy: 9.9896e-04 - factorized_top_k/top_100_categorical_accuracy: 0.0019 - loss: 35221.3683 - regularization_loss: 0.0000e+00 - total_loss: 35221.3683\n",
            "Top-100 accuracy (train): 0.72.\n",
            "Top-100 accuracy (test): 0.00.\n"
          ]
        }
      ],
      "source": [
        "# train the combined_model\n",
        "combined_model.fit(cached_train, epochs=5)\n",
        "\n",
        "train_accuracy = combined_model.evaluate(\n",
        "    cached_train, return_dict=True)[\"factorized_top_k/top_10_categorical_accuracy\"]\n",
        "test_accuracy = combined_model.evaluate(\n",
        "    cached_test, return_dict=True)[\"factorized_top_k/top_10_categorical_accuracy\"]\n",
        "\n",
        "print(f\"Top-10 accuracy (train): {train_accuracy:.2f}.\")\n",
        "print(f\"Top-10 accuracy (test): {test_accuracy:.2f}.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate model\n",
        "combined_model.evaluate(cached_test, return_dict=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROJIr9fJEzkN",
        "outputId": "90e104fe-325c-4f92-ec83-cf262471ea87"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 104s 17s/step - factorized_top_k/top_1_categorical_accuracy: 4.3433e-05 - factorized_top_k/top_5_categorical_accuracy: 1.7373e-04 - factorized_top_k/top_10_categorical_accuracy: 2.6060e-04 - factorized_top_k/top_50_categorical_accuracy: 9.9896e-04 - factorized_top_k/top_100_categorical_accuracy: 0.0019 - loss: 35221.3689 - regularization_loss: 0.0000e+00 - total_loss: 35221.3689\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'factorized_top_k/top_1_categorical_accuracy': 4.343294131103903e-05,\n",
              " 'factorized_top_k/top_5_categorical_accuracy': 0.00017373176524415612,\n",
              " 'factorized_top_k/top_10_categorical_accuracy': 0.0002605976478662342,\n",
              " 'factorized_top_k/top_50_categorical_accuracy': 0.000998957664705813,\n",
              " 'factorized_top_k/top_100_categorical_accuracy': 0.0018676164327189326,\n",
              " 'loss': 23408.94140625,\n",
              " 'regularization_loss': 0,\n",
              " 'total_loss': 23408.94140625}"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Even though the combined model performed well during the training and resulted in accuracy rate of 72.15% for Top-10 recommendations, it performed poorly on the test data resulting at 0.02% accuracy. "
      ],
      "metadata": {
        "id": "hNZf0Wv1G5kl"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BS6odru-kMb"
      },
      "source": [
        "### BruteForce serving"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "7P-UL8EMPQVL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25d992c7-d9d0-47a7-a20c-dc2bb9bb55d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recommendations for user 52228204: [b'Micro Pedalflow' b'K2 55 mm Wheel (4-pack)'\n",
            " b'SRAM FORCE Rear Derailleur WiFli- Medium'\n",
            " b'Plastic Black Nomad Sunglasses (1-Pack of 12)'\n",
            " b'Plastic Black Nomad Sunglasses (1-Pack of 12)'\n",
            " b'Plastic Black Nomad Sunglasses (1-Pack of 12)'\n",
            " b\"Waterprood R30 8oz Women's Long Sleeve Rashgaurd\"\n",
            " b\"Waterprood R30 8oz Women's Long Sleeve Rashgaurd\"\n",
            " b'Wald 1392 Standard Large Front Handlebar Bike Basket'\n",
            " b\"O'Neill Heat 3Q Zip 4/3 FSW (Black)\"]\n"
          ]
        }
      ],
      "source": [
        "# recommending Top-10 products for customer 52228204\n",
        "\n",
        "# Create a combined_model that takes in raw query features, and\n",
        "index = tfrs.layers.factorized_top_k.BruteForce(combined_model.candidate_model)\n",
        "# recommends products out of the entire products dataset.\n",
        "index.index_from_dataset(\n",
        "  tf.data.Dataset.zip((products.batch(100), products.batch(100).map(combined_model.candidate_model)))\n",
        ")\n",
        "\n",
        "# Get recommendations.\n",
        "_, titles = index(tf.constant([\"52228204\"]))\n",
        "print(f\"Recommendations for user 52228204: {titles[0, :10]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGTLhhsYDyen"
      },
      "source": [
        "There is still some repetition of recommendations, but not as extreme as in the basemodel. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "6wwii7quPXOb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96eb8833-01ce-4ef5-9418-5a345439ee2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as query_with_exclusions while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recommendations: [b'Micro Pedalflow' b'K2 55 mm Wheel (4-pack)'\n",
            " b'SRAM FORCE Rear Derailleur WiFli- Medium']\n"
          ]
        }
      ],
      "source": [
        "# model serving: saving the model to G-Drive\n",
        "\n",
        "# Export the query model.\n",
        "gdrive_path = '/content/drive/MyDrive/Models'\n",
        "path = os.path.join(gdrive_path, \"combined_model\")\n",
        "\n",
        "# Save the index.\n",
        "tf.saved_model.save(index, path)\n",
        "\n",
        "# Load it back; can also be done in TensorFlow Serving.\n",
        "combined_model_2 = tf.saved_model.load(path)\n",
        "\n",
        "# Pass a user id in, get top predicted movie titles back.\n",
        "scores, titles = combined_model_2([\"52228204\"])\n",
        "\n",
        "print(f\"Recommendations: {titles[0][:3]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ScaNN"
      ],
      "metadata": {
        "id": "-H3seVpf8ySp"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yWoax75-Jax"
      },
      "source": [
        "Adding ScaNN layer for quick retrieval and saving it to G-Drive. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "mSa5LPrOPzEW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afb24f7b-e333-4559-bf60-ceb71b2e8b5d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow_recommenders.layers.factorized_top_k.ScaNN at 0x7f2b3b28f490>"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ],
      "source": [
        "# adding ScaNN layer\n",
        "scann_index = tfrs.layers.factorized_top_k.ScaNN(combined_model.candidate_model)\n",
        "scann_index.index_from_dataset(\n",
        "  tf.data.Dataset.zip((products.batch(100), products.batch(100).map(combined_model.candidate_model)))\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "NAhZyK-VP_yj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e49494bd-73ac-4716-c1c3-ed7ebc3891a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recommendations for user 52228204: [b'Micro Pedalflow' b'SNOWBOARD BINDINGS XL strap in Snowjam XL black NEW'\n",
            " b'K2 55 mm Wheel (4-pack)' b\"O'Neill Heat 3Q Zip 4/3 FSW (Black)\"\n",
            " b'Shimano RD-M773-10 XTShadow Rear Derailleur - 10Sp SGS Black/Silver'\n",
            " b'Fox Labs FX-42H Mark 5 Cop Top 4oz Stream Pepper Spray'\n",
            " b'Wald 1392 Standard Large Front Handlebar Bike Basket'\n",
            " b'Swisstop RacePro Brake Pads (fits Camp 10/11sp)'\n",
            " b'OXO - Good Grips Bagel Grip' b'OXO - Good Grips Bagel Grip']\n"
          ]
        }
      ],
      "source": [
        "# Get recommendations.\n",
        "_, titles = scann_index(tf.constant([\"52228204\"]))\n",
        "print(f\"Recommendations for user 52228204: {titles[0, :10]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "slPopwxhQEJc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8baf44c0-342a-4a49-f70a-ee8633437d07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as query_with_exclusions while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recommendations: [b'Micro Pedalflow' b'K2 55 mm Wheel (4-pack)'\n",
            " b'SRAM FORCE Rear Derailleur WiFli- Medium'\n",
            " b'Plastic Black Nomad Sunglasses (1-Pack of 12)'\n",
            " b'Plastic Black Nomad Sunglasses (1-Pack of 12)'\n",
            " b'Plastic Black Nomad Sunglasses (1-Pack of 12)'\n",
            " b\"Waterprood R30 8oz Women's Long Sleeve Rashgaurd\"\n",
            " b\"Waterprood R30 8oz Women's Long Sleeve Rashgaurd\"\n",
            " b'Wald 1392 Standard Large Front Handlebar Bike Basket'\n",
            " b\"O'Neill Heat 3Q Zip 4/3 FSW (Black)\"]\n"
          ]
        }
      ],
      "source": [
        "# exporting ScaNN layer\n",
        "\n",
        "# Export the query model.\n",
        "gdrive_path = '/content/drive/MyDrive/Models'\n",
        "path = os.path.join(gdrive_path, \"combined_model\")\n",
        "\n",
        "# Save the index.\n",
        "tf.saved_model.save(\n",
        "    index,\n",
        "    path,\n",
        "    options=tf.saved_model.SaveOptions(namespace_whitelist=[\"Scann\"])\n",
        ")\n",
        "\n",
        "# Load it back; can also be done in TensorFlow Serving.\n",
        "combined_model_2 = tf.saved_model.load(path)\n",
        "\n",
        "# Pass a user id in, get top predicted movie titles back.\n",
        "scores, titles = combined_model_2([\"52228204\"])\n",
        "\n",
        "print(f\"Recommendations: {titles[0][:10]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1w22jXW9Pfz"
      },
      "source": [
        "Even though the combined model performed well during the training and resulted in accuracy rate of 72.15% for Top-10 recommendations, it performed poorly on the test data resulting at 0.02% accuracy.\n",
        "\n",
        "Out of 10 recommendations, I found one to be useful for this customer. "
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2uOMn9qxIYvI"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}