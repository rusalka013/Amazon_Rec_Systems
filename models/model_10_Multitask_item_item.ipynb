{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Multitask Recommender with item-item Retrieval model. "
      ],
      "metadata": {
        "id": "cWHF2-ZOkcaS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will build a multi-task recommender with using both implicit (product clicks) and explicit signals (ratings). Ranking and Retrieval stages will be used. For this model we will use item-to-item Retrieval model.\n",
        "\n"
      ],
      "metadata": {
        "id": "SrSqld1bkgDz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multitask Model"
      ],
      "metadata": {
        "id": "ZY5AZczlm_jI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ],
      "metadata": {
        "id": "Klrwx7KllxBm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "dOxGhpXPkPlI",
        "outputId": "23907329-a8c9-401b-a648-53b722905acf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.9.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.9.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.27.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.1.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.49.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.2.0)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.9.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.9.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (14.0.6)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (5.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (3.9.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (3.2.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow) (3.0.9)\n"
          ]
        }
      ],
      "source": [
        "! pip install tensorflow\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -q tensorflow-recommenders\n",
        "! pip install -q --upgrade tensorflow-datasets\n",
        "! pip install -q scann"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "t5GOFmmJk_kk",
        "outputId": "d288c5f5-9196-4ce0-d4f8-5aaa41b70041"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 89 kB 3.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.7 MB 4.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 10.4 MB 4.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 578.0 MB 15 kB/s \n",
            "\u001b[K     |████████████████████████████████| 438 kB 53.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 68.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 5.9 MB 34.8 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pprint\n",
        "import tempfile\n",
        "\n",
        "from typing import Dict, Text\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow_recommenders as tfrs\n",
        "\n",
        "# import interactive table \n",
        "from google.colab import data_table\n",
        "data_table.enable_dataframe_formatter()\n",
        "\n",
        "# set seed\n",
        "tf.random.set_seed(42)"
      ],
      "metadata": {
        "id": "hLsz6MVhlEez"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "3vNFTwEqlnJ1",
        "outputId": "bdf4f3b4-c9e0-484f-824a-ffacd4daca7a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparing Dataset"
      ],
      "metadata": {
        "id": "ibZGvgLCl2xX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load data subset \n",
        "gdrive_path = '/content/drive/MyDrive/ModelingData'\n",
        "path = os.path.join(gdrive_path, \"ratings\")\n",
        "\n",
        "ratings = tf.data.Dataset.load(path)"
      ],
      "metadata": {
        "id": "pOMfPJ6zlUpA"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select the basic features.\n",
        "ratings = ratings.map(lambda x: {\n",
        "    'product_title': x['data']['product_title'], \n",
        "    'customer_id': x['data']['customer_id'], \n",
        "    'star_rating': x['data']['star_rating']\n",
        "})\n",
        "products = ratings.map(lambda x: x['product_title'])"
      ],
      "metadata": {
        "id": "r5dluF84lcz2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train-test split\n",
        "tf.random.set_seed(42)\n",
        "shuffled = ratings.shuffle(92_096, seed=42, reshuffle_each_iteration=False)\n",
        "\n",
        "train = shuffled.take(92_096)\n",
        "test = shuffled.skip(92_096).take(23_024)"
      ],
      "metadata": {
        "id": "RFHPwvnEmc9T"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vocabulary to map raw feature values to embedding vectors\n",
        "product_titles = products.batch(50_000)\n",
        "customer_ids = ratings.batch(110_000).map(lambda x: x['customer_id'])\n",
        "\n",
        "unique_product_titles = np.unique(np.concatenate(list(product_titles)))\n",
        "unique_customer_ids = np.unique(np.concatenate(list(customer_ids)))"
      ],
      "metadata": {
        "id": "QX2U3MkGmkoU"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implementing the model"
      ],
      "metadata": {
        "id": "ljsUI92QnGfw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are two critical parts to multi-task recommenders:\n",
        "\n",
        "They optimize for two or more objectives, and so have two or more losses.\n",
        "They share variables between the tasks, allowing for transfer learning.\n",
        "In this tutorial, we will define our models as before, but instead of having a single task, we will have two tasks: one that predicts ratings, and one that predicts movie watches.\n",
        "\n",
        "The user and movie models are as before:"
      ],
      "metadata": {
        "id": "Iu0vnyfAnNsz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dimension = 32\n",
        "\n",
        "user_model = tf.keras.Sequential([\n",
        "  tf.keras.layers.StringLookup(\n",
        "      vocabulary=unique_customer_ids, mask_token=None),\n",
        "  # We add 1 to account for the unknown token.\n",
        "  tf.keras.layers.Embedding(len(unique_customer_ids) + 1, embedding_dimension)\n",
        "])\n",
        "\n",
        "product_model = tf.keras.Sequential([\n",
        "  tf.keras.layers.StringLookup(\n",
        "      vocabulary=unique_product_titles, mask_token=None),\n",
        "  tf.keras.layers.Embedding(len(unique_product_titles) + 1, embedding_dimension)\n",
        "])"
      ],
      "metadata": {
        "id": "EnZivPyYmy-i"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will have two tasks: Ranking and Retrieval. "
      ],
      "metadata": {
        "id": "R3QbsP8hn2K-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfrs.tasks.Ranking(\n",
        "    loss=tf.keras.losses.MeanSquaredError(),\n",
        "    metrics=[tf.keras.metrics.RootMeanSquaredError()],\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNOfKAvgny5f",
        "outputId": "10d7bb22-2ab6-4180-f469-e62f6cd37555"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow_recommenders.tasks.ranking.Ranking at 0x7f9044b7db50>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tfrs.tasks.Retrieval(\n",
        "    metrics=tfrs.metrics.FactorizedTopK(\n",
        "        candidates=products.batch(128)\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nIc2o4Uvn_o4",
        "outputId": "b71de8b1-e4a7-4d6d-ddd0-2ac0e58840a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow_recommenders.tasks.retrieval.Retrieval at 0x7f9044ce7a50>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The new component here is that - since we have two tasks and two losses - we need to decide on how important each loss is. We can do this by giving each of the losses a weight, and treating these weights as hyperparameters. If we assign a large loss weight to the rating task, our model is going to focus on predicting ratings (but still use some information from the retrieval task); if we assign a large loss weight to the retrieval task, it will focus on retrieval instead."
      ],
      "metadata": {
        "id": "1-UaLIH5pRxg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define a model\n",
        "class AmazonModel(tfrs.models.Model):\n",
        "\n",
        "  def __init__(self, rating_weight: float, retrieval_weight: float) -> None:\n",
        "    # We take the loss weights in the constructor: this allows us to instantiate\n",
        "    # several model objects with different loss weights.\n",
        "\n",
        "    super().__init__()\n",
        "\n",
        "    embedding_dimension = 32\n",
        "\n",
        "    # User and product models.\n",
        "    self.product_model: tf.keras.layers.Layer = tf.keras.Sequential([\n",
        "      tf.keras.layers.StringLookup(\n",
        "        vocabulary=unique_product_titles, mask_token=None),\n",
        "      tf.keras.layers.Embedding(len(unique_product_titles) + 1, embedding_dimension)\n",
        "    ])\n",
        "    self.user_model: tf.keras.layers.Layer = tf.keras.Sequential([\n",
        "      tf.keras.layers.StringLookup(\n",
        "        vocabulary=unique_product_titles, mask_token=None),\n",
        "      tf.keras.layers.Embedding(len(unique_product_titles) + 1, embedding_dimension)\n",
        "    ])\n",
        "\n",
        "    # A small model to take in user and product embeddings and predict ratings.\n",
        "    # We can make this as complicated as we want as long as we output a scalar\n",
        "    # as our prediction.\n",
        "    self.rating_model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(256, activation=\"relu\"),\n",
        "        tf.keras.layers.Dense(128, activation=\"relu\"),\n",
        "        tf.keras.layers.Dense(1),\n",
        "    ])\n",
        "\n",
        "    # The tasks.\n",
        "    self.rating_task: tf.keras.layers.Layer = tfrs.tasks.Ranking(\n",
        "        loss=tf.keras.losses.MeanSquaredError(),\n",
        "        metrics=[tf.keras.metrics.RootMeanSquaredError()],\n",
        "    )\n",
        "    self.retrieval_task: tf.keras.layers.Layer = tfrs.tasks.Retrieval(\n",
        "        metrics=tfrs.metrics.FactorizedTopK(\n",
        "            candidates=products.batch(128).map(self.product_model)\n",
        "        )\n",
        "    )\n",
        "\n",
        "    # The loss weights.\n",
        "    self.rating_weight = rating_weight\n",
        "    self.retrieval_weight = retrieval_weight\n",
        "\n",
        "  def call(self, features: Dict[Text, tf.Tensor]) -> tf.Tensor:\n",
        "    # We pick out the user features and pass them into the user model.\n",
        "    user_embeddings = self.user_model(features[\"product_title\"])\n",
        "    # And pick out the product features and pass them into the product model.\n",
        "    product_embeddings = self.product_model(features[\"product_title\"])\n",
        "\n",
        "    return (\n",
        "        user_embeddings,\n",
        "        product_embeddings,\n",
        "        # We apply the multi-layered rating model to a concatentation of\n",
        "        # user and product embeddings.\n",
        "        self.rating_model(\n",
        "            tf.concat([user_embeddings, product_embeddings], axis=1)\n",
        "        ),\n",
        "    )\n",
        "\n",
        "  def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
        "\n",
        "    ratings = features.pop(\"star_rating\")\n",
        "\n",
        "    user_embeddings, product_embeddings, rating_predictions = self(features)\n",
        "\n",
        "    # We compute the loss for each task.\n",
        "    rating_loss = self.rating_task(\n",
        "        labels=ratings,\n",
        "        predictions=rating_predictions,\n",
        "    )\n",
        "    retrieval_loss = self.retrieval_task(user_embeddings, product_embeddings)\n",
        "\n",
        "    # And combine them using the loss weights.\n",
        "    return (self.rating_weight * rating_loss\n",
        "            + self.retrieval_weight * retrieval_loss)"
      ],
      "metadata": {
        "id": "wqC9vAjXoCzr"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Rating-specialized model"
      ],
      "metadata": {
        "id": "IIGcnGIUpaPD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will start with model that only considers ratings. "
      ],
      "metadata": {
        "id": "V0jJoKovpfJo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rating_model = AmazonModel(rating_weight=1.0, retrieval_weight=0.0)\n",
        "rating_model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))"
      ],
      "metadata": {
        "id": "Xt3pihMPpbYG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# shuffle, batch, and cache train and test data\n",
        "cached_train = train.shuffle(100_000).batch(8192).cache()\n",
        "cached_test = test.batch(4096).cache()"
      ],
      "metadata": {
        "id": "Oi9aN7YfqGEn"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rating_model.fit(cached_train, epochs=3)\n",
        "metrics = rating_model.evaluate(cached_test, return_dict=True)\n",
        "\n",
        "print(f\"Retrieval top-100 accuracy: {metrics['factorized_top_k/top_100_categorical_accuracy']:.3f}.\")\n",
        "print(f\"Ranking RMSE: {metrics['root_mean_squared_error']:.3f}.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHpcBDG4qNoc",
        "outputId": "b8675254-f427-4362-920e-ba57812b272b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "12/12 [==============================] - 1274s 105s/step - root_mean_squared_error: 2.4213 - factorized_top_k/top_1_categorical_accuracy: 1.0858e-05 - factorized_top_k/top_5_categorical_accuracy: 6.5149e-05 - factorized_top_k/top_10_categorical_accuracy: 7.6008e-05 - factorized_top_k/top_50_categorical_accuracy: 4.9948e-04 - factorized_top_k/top_100_categorical_accuracy: 9.3381e-04 - loss: 5.2712 - regularization_loss: 0.0000e+00 - total_loss: 5.2712\n",
            "Epoch 2/3\n",
            "12/12 [==============================] - 1284s 107s/step - root_mean_squared_error: 1.2111 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 6.5149e-05 - factorized_top_k/top_10_categorical_accuracy: 7.6008e-05 - factorized_top_k/top_50_categorical_accuracy: 5.1034e-04 - factorized_top_k/top_100_categorical_accuracy: 9.3381e-04 - loss: 1.4649 - regularization_loss: 0.0000e+00 - total_loss: 1.4649\n",
            "Epoch 3/3\n",
            "12/12 [==============================] - 1258s 104s/step - root_mean_squared_error: 1.2088 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 6.5149e-05 - factorized_top_k/top_10_categorical_accuracy: 7.6008e-05 - factorized_top_k/top_50_categorical_accuracy: 5.2120e-04 - factorized_top_k/top_100_categorical_accuracy: 9.4467e-04 - loss: 1.4599 - regularization_loss: 0.0000e+00 - total_loss: 1.4599\n",
            "6/6 [==============================] - 342s 55s/step - root_mean_squared_error: 1.2214 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 4.3433e-05 - factorized_top_k/top_10_categorical_accuracy: 8.6866e-05 - factorized_top_k/top_50_categorical_accuracy: 6.9493e-04 - factorized_top_k/top_100_categorical_accuracy: 0.0013 - loss: 1.4959 - regularization_loss: 0.0000e+00 - total_loss: 1.4959\n",
            "Retrieval top-100 accuracy: 0.001.\n",
            "Ranking RMSE: 1.221.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Retrieval-specialized model"
      ],
      "metadata": {
        "id": "7A0DuKn_xFSQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retrieval_model = AmazonModel(rating_weight=0.0, retrieval_weight=1.0)\n",
        "retrieval_model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))"
      ],
      "metadata": {
        "id": "zM8wvsx3xMrs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retrieval_model.fit(cached_train, epochs=3)\n",
        "metrics = retrieval_model.evaluate(cached_test, return_dict=True)\n",
        "\n",
        "print(f\"Retrieval top-100 accuracy: {metrics['factorized_top_k/top_100_categorical_accuracy']:.3f}.\")\n",
        "print(f\"Ranking RMSE: {metrics['root_mean_squared_error']:.3f}.\")"
      ],
      "metadata": {
        "id": "0Mm5MXLUxcE8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Joint model"
      ],
      "metadata": {
        "id": "64sOFaXnxix7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assigning equal weights to both tasks. "
      ],
      "metadata": {
        "id": "sifJYMgs669t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "joint_model = AmazonModel(rating_weight=1.0, retrieval_weight=1.0)\n",
        "joint_model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))"
      ],
      "metadata": {
        "id": "10nsWrVQxkwS"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "joint_model.fit(cached_train, epochs=3)\n",
        "metrics = joint_model.evaluate(cached_test, return_dict=True)\n",
        "\n",
        "print(f\"Retrieval top-100 accuracy: {metrics['factorized_top_k/top_100_categorical_accuracy']:.3f}.\")\n",
        "print(f\"Ranking RMSE: {metrics['root_mean_squared_error']:.3f}.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "u3JxvmTCxtLp",
        "outputId": "402b28dd-9362-4265-856f-b4c3f277042b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "12/12 [==============================] - 1301s 107s/step - root_mean_squared_error: 2.7123 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 2.1716e-05 - factorized_top_k/top_50_categorical_accuracy: 0.0544 - factorized_top_k/top_100_categorical_accuracy: 0.0958 - loss: 61713.2886 - regularization_loss: 0.0000e+00 - total_loss: 61713.2886\n",
            "Epoch 2/3\n",
            "12/12 [==============================] - 1365s 114s/step - root_mean_squared_error: 1.2147 - factorized_top_k/top_1_categorical_accuracy: 0.0122 - factorized_top_k/top_5_categorical_accuracy: 0.0139 - factorized_top_k/top_10_categorical_accuracy: 0.0188 - factorized_top_k/top_50_categorical_accuracy: 0.2136 - factorized_top_k/top_100_categorical_accuracy: 0.2628 - loss: 51142.6668 - regularization_loss: 0.0000e+00 - total_loss: 51142.6668\n",
            "Epoch 3/3\n",
            "12/12 [==============================] - 1371s 112s/step - root_mean_squared_error: 1.5115 - factorized_top_k/top_1_categorical_accuracy: 0.0781 - factorized_top_k/top_5_categorical_accuracy: 0.0899 - factorized_top_k/top_10_categorical_accuracy: 0.1502 - factorized_top_k/top_50_categorical_accuracy: 0.3576 - factorized_top_k/top_100_categorical_accuracy: 0.3874 - loss: 43613.6424 - regularization_loss: 0.0000e+00 - total_loss: 43613.6424\n",
            "6/6 [==============================] - 357s 58s/step - root_mean_squared_error: 1.3193 - factorized_top_k/top_1_categorical_accuracy: 0.2538 - factorized_top_k/top_5_categorical_accuracy: 0.2538 - factorized_top_k/top_10_categorical_accuracy: 0.2765 - factorized_top_k/top_50_categorical_accuracy: 0.3653 - factorized_top_k/top_100_categorical_accuracy: 0.3882 - loss: 19507.3856 - regularization_loss: 0.0000e+00 - total_loss: 19507.3856\n",
            "Retrieval top-100 accuracy: 0.388.\n",
            "Ranking RMSE: 1.319.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy rate at 38.8% for Top-100 recs on test data. "
      ],
      "metadata": {
        "id": "K-AoltMqLuuX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Serving and saving the model"
      ],
      "metadata": {
        "id": "OGZY-r0KYYN5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# making predictions\n",
        "trained_product_embeddings, trained_customer_embeddings, predicted_rating = joint_model({\n",
        "      \"customer_id\": np.array([\"52228204\"]),\n",
        "      \"product_title\": np.array([\"Vader Bicycle Cycling Bike Road Offroad MTB Mountain Saddle Seat\"])\n",
        "  })\n",
        "print(\"Predicted rating:\")\n",
        "print(predicted_rating)"
      ],
      "metadata": {
        "id": "mkKPIxU5L8A3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "d6d99792-98a8-4cb4-895c-36f781b78c6b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted rating:\n",
            "tf.Tensor([[4.7740483]], shape=(1, 1), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# recommending Top-10 products for customer 52228204\n",
        "\n",
        "# Create a joint_model that takes in raw query features, and\n",
        "index = tfrs.layers.factorized_top_k.BruteForce(joint_model.product_model)\n",
        "# recommends products out of the entire products dataset.\n",
        "index.index_from_dataset(\n",
        "  tf.data.Dataset.zip((products.batch(100), products.batch(100).map(joint_model.product_model)))\n",
        ")\n",
        "\n",
        "# Get recommendations.\n",
        "_, titles = index(tf.constant([\"52228204\"]))\n",
        "print(f\"Recommendations for user 52228204: {titles[0, :10]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "u8jaxBCIX74y",
        "outputId": "06eac305-c34c-4c4c-e711-40d0cd93fd13"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recommendations for user 52228204: [b'Coleman Converta Cot' b'Coleman Converta Cot' b'Coleman Converta Cot'\n",
            " b'Coleman Converta Cot' b'Coleman Converta Cot' b'Coleman Converta Cot'\n",
            " b'Coleman Converta Cot' b'Coleman Converta Cot' b'Coleman Converta Cot'\n",
            " b'Coleman Converta Cot']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model serving: saving the model to G-Drive\n",
        "\n",
        "# Export the query model.\n",
        "gdrive_path = '/content/drive/MyDrive/Models'\n",
        "path = os.path.join(gdrive_path, \"joint_model\")\n",
        "\n",
        "# Save the index.\n",
        "tf.saved_model.save(index, path)\n",
        "\n",
        "# Load it back; can also be done in TensorFlow Serving.\n",
        "joint_model_2 = tf.saved_model.load(path)\n",
        "\n",
        "# Pass a user id in, get top predicted movie titles back.\n",
        "scores, titles = joint_model_2([\"52228204\"])\n",
        "\n",
        "print(f\"Recommendations: {titles[0][:3]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Wn6FE3tJYjWB",
        "outputId": "ed71aa0c-d7e0-45d3-e0b3-b9c9315d09f7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as query_with_exclusions while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recommendations: [b'Coleman Converta Cot' b'Coleman Converta Cot' b'Coleman Converta Cot']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# adding ScaNN layer\n",
        "scann_index = tfrs.layers.factorized_top_k.ScaNN(joint_model.product_model)\n",
        "scann_index.index_from_dataset(\n",
        "  tf.data.Dataset.zip((products.batch(100), products.batch(100).map(joint_model.product_model)))\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "GLMqhnVQYnzq",
        "outputId": "6f876355-e670-43fe-d002-e150dd496654"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow_recommenders.layers.factorized_top_k.ScaNN at 0x7f2878f207d0>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get recommendations.\n",
        "_, titles = scann_index(tf.constant([\"52228204\"]))\n",
        "print(f\"Recommendations for user 52228204: {titles[0, :10]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "aKqW0M42Y_uW",
        "outputId": "e0d4d9c6-69fe-47d2-e715-34bbaf27fc86"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recommendations for user 52228204: [b'TravelJohn-Disposable Urinal (6 pack)'\n",
            " b'TravelJohn-Disposable Urinal (6 pack)'\n",
            " b'TravelJohn-Disposable Urinal (6 pack)'\n",
            " b'TravelJohn-Disposable Urinal (6 pack)'\n",
            " b'TravelJohn-Disposable Urinal (6 pack)'\n",
            " b'TravelJohn-Disposable Urinal (6 pack)'\n",
            " b'TravelJohn-Disposable Urinal (6 pack)'\n",
            " b'TravelJohn-Disposable Urinal (6 pack)'\n",
            " b'TravelJohn-Disposable Urinal (6 pack)'\n",
            " b'TravelJohn-Disposable Urinal (6 pack)']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# exporting ScaNN layer\n",
        "\n",
        "# Export the query model.\n",
        "gdrive_path = '/content/drive/MyDrive/Models'\n",
        "path = os.path.join(gdrive_path, \"joint_model\")\n",
        "\n",
        "# Save the index.\n",
        "tf.saved_model.save(\n",
        "    index,\n",
        "    path,\n",
        "    options=tf.saved_model.SaveOptions(namespace_whitelist=[\"Scann\"])\n",
        ")\n",
        "\n",
        "# Load it back; can also be done in TensorFlow Serving.\n",
        "joint_model_2 = tf.saved_model.load(path)\n",
        "\n",
        "# Pass a user id in, get top predicted movie titles back.\n",
        "scores, titles = joint_model_2([\"52228204\"])\n",
        "\n",
        "print(f\"Recommendations: {titles[0][:10]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "l3a1vZ-FZLko",
        "outputId": "f8c3a44d-e102-4e06-868b-bc1f71be95f8"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as query_with_exclusions while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recommendations: [b'Coleman Converta Cot' b'Coleman Converta Cot' b'Coleman Converta Cot'\n",
            " b'Coleman Converta Cot' b'Coleman Converta Cot' b'Coleman Converta Cot'\n",
            " b'Coleman Converta Cot' b'Coleman Converta Cot' b'Coleman Converta Cot'\n",
            " b'Coleman Converta Cot']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy rate at 38.8% for Top-100 recs on test data. Recommendations have a lot of repeats. "
      ],
      "metadata": {
        "id": "numjMsVLvH7c"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tfKgqBn_vIje"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}